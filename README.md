# FYP-65 Resume Intelligence Toolkit

## Project Overview
- **Purpose** Transform raw resume data into structured, analyzable datasets and build classifiers for resume categorization.
- **Scope** End-to-end utilities for CSV datasets, PDF parsing, and supervised classification pipelines.
- **Stack** Python-based scripts leveraging `pandas`, `PyPDF2`, `nltk`, and `scikit-learn`.

## Repository Structure
- **`resume_feature_engineering.py`** Feature engineering workflow for CSV resume datasets with skills, education, and experience extraction.
- **`pdf_resume_feature_engineering.py`** PDF ingestion pipeline that converts folders of resumes into tabular summaries.
- **`resume_classifier.py`** Machine learning training CLI that supports Naive Bayes and Logistic Regression models for resume categorization.
- **`DATA/`** Placeholder directory for raw inputs (CSV or categorized PDF folders). Populate with your datasets before running scripts.
- **`pdf_resumes_features.csv` / `pdf_resumes_features.xlsx`** Example outputs generated by the PDF feature pipeline.

## Prerequisites
- **Python** 3.10+ recommended.
- **Packages** Install dependencies in the active environment:
  ```bash
  pip install pandas scikit-learn nltk PyPDF2 openpyxl
  ```
- **NLTK Data** First run will auto-download required corpora; ensure internet connectivity or pre-download via:
  ```python
  import nltk
  for resource in ["punkt", "punkt_tab", "stopwords", "wordnet", "omw-1.4"]:
      nltk.download(resource)
  ```

## Usage
- **CSV Feature Engineering**
  ```bash
  python resume_feature_engineering.py \
    --input-csv DATA/resumes.csv \
    --output-csv processed_resumes.csv \
    --output-excel processed_resumes.xlsx \
    --skill-file skills.txt \
    --sample-rows 10
  ```
  - **`--skill-file`** optional newline-separated list to override default skill vocabulary.

- **PDF Feature Extraction**
  ```bash
  python pdf_resume_feature_engineering.py \
    --pdf-dir DATA/pdf_resumes \
    --output-csv pdf_resumes_features.csv \
    --output-excel pdf_resumes_features.xlsx \
    --sample-rows 10
  ```
  - Provide a flat directory of PDF files; summary columns include `Skills`, `Education`, and `Marks`.

- **Resume Classification Pipeline**
  ```bash
  python resume_classifier.py \
    --data-path DATA/resumes.csv \
    --model-type logistic_regression \
    --test-size 0.2 \
    --predict-text "Senior data analyst with Python and SQL experience"
  ```
  - Accepts CSV (`Category`, `Resume`) or directory of category-labelled PDF folders.
  - Outputs accuracy, classification report, confusion matrix, and optional inference on provided text.

## Customization Tips
- **Skills Vocabulary** Adjust the lists in `resume_feature_engineering.py` and `pdf_resume_feature_engineering.py` or supply external skill files.
- **Feature Outputs** Modify column engineering logic (`augment_dataset()` or `extract_features_from_pdf()`) to match domain needs.
- **Model Choices** Extend `resume_classifier.py` with additional algorithms or tweak TF-IDF parameters in `build_vectorizer()`.

## Suggested Workflow
- **Step 1** Generate enriched CSV data from raw resumes using either CSV or PDF pipeline.
- **Step 2** Feed the processed dataset into `resume_classifier.py` to train and evaluate classifiers.
- **Step 3** Iterate on vocabularies, pre-processing, and model hyperparameters based on evaluation metrics.

## Troubleshooting
- **Missing PDF Text** Some PDFs may have non-extractable text; consider pre-processing with OCR tools.
- **NLTK Lookup Errors** Ensure corpora download successfully or set `NLTK_DATA` environment variable to a writable path.
- **Excel Export Errors** Install `openpyxl` if `to_excel()` raises an engine error.

## Contributions & License
- **Contributions** Fork and submit pull requests with clear descriptions and reproducible examples.
- **License** Not specified; update this section once a license is chosen for the project.
